from langgraph.graph import StateGraph, END, START
from langchain_openai import ChatOpenAI
from langchain_core.tools import tool
import os
from dotenv import load_dotenv
from typing import Annotated, TypedDict, Optional
from langgraph.graph.message import add_messages
from langchain.agents.factory import create_agent

load_dotenv()

if not os.getenv("OPENAI_API_KEY"):
    raise ValueError("OPENAI_API_KEY is not set in .env file")

# Test tool
@tool
def retrieval_tool(query: str) -> str:
    """
    Retrieve information based on a query generated by the Planning/Router agent.

    Parameters
    ----------
    query : str
        A structured query indicating what data to fetch from private or live
        data sources.

    Returns
    -------
    str
        A minimally formatted string representing the raw retrieved information
        associated with the query.
    """
    print(f"RETRIEVAL TOOL Invoked with {query}:")
    return f"Retrieved information for query: {query}"


class AgentState(dict):
    # messages: Annotated[list, add_messages]
    input: str
    response: str
    done: bool

    intent: Optional[str]
    plan: Optional[str]
    knowledge: Optional[str]



llm = ChatOpenAI(model="gpt-4", temperature=0)

# @tool
# def retrieval_tool(query: str) -> str:
#     return f"Retrieved information for query: {query}"


def router_node(state: AgentState) -> str:
    print("ROUTER NODE Started")
    user_input = state['input']
    system_prompt = f"""You are the Router Agent. Read the user request and:
1) Identify the main task.
2) Extract constraints (budget, materials, brands).
3) Detect any safety concerns and flag them if necessary.

USER REQUEST:
{user_input}

Your response MUST follow this format:

* Task:
* Constraints:
  - Budget:
  - Material:
  - Brand:
* Safety Flags: (Yes/No — if Yes, provide a brief reason)
"""

    response = llm.invoke(system_prompt)
    return {"intent": response.content}

    
def planner_node(state: AgentState) -> str:
    print("Planner NODE Started")
    intent = state.get('intent', 'No intent provided')
    system_prompt = f"""You are the Planning Agent. Based on the user's intent, you must plan how to retrieve data.

Your responsibilities:
1) Choose the data source(s): **private**, **live**, or **both**
    • Use **private** for catalog-style data (product descriptions, ratings, prices, ingredients).
    • Use **live** for real-time or external information not stored in the private catalog.
    • Use **both** if the request needs a mix of catalog and live data.
2) Identify which fields must be retrieved.
3) Determine the comparison criteria used to evaluate options (e.g., price, quality, rating, ingredients, durability).

Intent:
{intent}

Your response MUST follow this format:

* Data Source (private / live / both):
* Fields to Retrieve:
* Comparison Criteria:
"""
    
    response = llm.invoke(system_prompt)
    return {"plan": response.content}
    

def retrieve_node(state: AgentState) -> str:
    print("Retriever NODE Started")
    rag_agent = create_agent(
        model=llm, 
        tools=[retrieval_tool]
        )
    
    plan = state.get('plan', 'No plan provided')
    system_prompt = f"""You are the Retrieval Agent. Your job is to fetch the information specified in the plan.

Rules:
• You MUST use retrieval_tool() to fetch data whenever retrieval is required by the plan.
• Return ONLY the requested data in raw or minimally structured form (do NOT summarize or interpret it).
• If the requested data cannot be retrieved, respond EXACTLY: "No data found."
• If the plan does not require retrieval, respond EXACTLY: "Retrieval not applicable."

Plan Details:
{plan}

Your response MUST follow this format:

* Retrieved data:
<insert data here or the exact required message>
"""
    rag_agent = create_agent(
        model=llm, 
        tools=[retrieval_tool]
        )
    
    plan = state['plan']
    system_prompt = f"""You are the Retrieval Agent. Your job is to fetch the information specified in the plan.

Rules:
• You MUST use retrieval_tool() to fetch data whenever retrieval is required by the plan.
• Return ONLY the requested data in raw or minimally structured form (do NOT summarize or interpret it).
• If the requested data cannot be retrieved, respond EXACTLY: "No data found."
• If the plan does not require retrieval, respond EXACTLY: "Retrieval not applicable."

Plan Details:
{plan}

Your response MUST follow this format:

* Retrieved data:
<insert data here or the exact required message>
"""
    response = rag_agent.invoke({"messages": [{"role": "user", "content": system_prompt}]})
    response
    return {'knowledge': response["messages"][-1].content}
    

def answer_critic_node(state: AgentState) -> str:
    print("Answer/Critic NODE Started")
    user_input = state['input']
    knowledge = state.get('knowledge', 'No knowledge provided')
    system_prompt = f"""You are the Answer Critic Agent. Your job is to synthesize a concise, cited recommendation; enforce grounding & safety.

Rules:
• Create a final answer that directly addresses the user's request using ONLY the retrieved knowledge.
• Cite specific data points from the retrieved knowledge to support your answer.
• If the retrieved knowledge contains safety concerns, flag them clearly in your answer.

User Request:
{user_input}

Retrieved Knowledge:
{knowledge}

Your response MUST follow this format:
* Final Answer:
<insert final answer with citations and safety notes if applicable>
"""
    response = llm.invoke(system_prompt)
    return {"response": response.content, "done": True}
    

graph = StateGraph(AgentState)

graph .add_node("Router", router_node)
graph .add_node("Planner", planner_node)
graph .add_node("Retriver", retrieve_node)
graph .add_node("Answer", answer_critic_node)

graph.add_edge(START, "Router")
graph.add_edge("Router", "Planner")
graph.add_edge("Planner", "Retriver")
graph.add_edge("Retriver", "Answer")
graph.add_conditional_edges("Answer", lambda state: "END" if state.get("done") else "Planner", {"Planeer": "Planner", "END": END})


app = graph.compile()

# test = app.invoke(
#     {'input': "I need an eco-friendly stainless-steel cleaner under $15"}, 
#     # {"messages": [{"role":"user", "content": "I need an eco-friendly stainless-steel cleaner under $15"}]},
# )
# print(test['response'])