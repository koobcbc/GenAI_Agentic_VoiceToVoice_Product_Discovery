{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03604825"
      },
      "source": [
        "# 1. Data Preprocessing & Parquet\n",
        "- Process the CSV file \"marketing_sample_for_amazon_com-ecommerce__20200101_20200131__10k_data.csv\"\n",
        "- Cleanup & Create two Parquet files:\n",
        "  - `products.parquet` (containing product `id`, `title`, `brand`, `category`, `price`, `rating`, `features`, and `ingredients`)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "116d8392"
      },
      "source": [
        "## Load CSV Data\n",
        "\n",
        "- Load the 'marketing_sample_for_amazon_com-ecommerce__20200101_20200131__10k_data.csv' file into a pandas DataFrame.\n",
        "- Inspect the column names to understand their structure before proceeding with extraction.\n",
        "\n",
        "Please Ensure to use your own path to the csv file when running the file"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bba60a4"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Modify to your path to CSV\n",
        "file_path = '/content/drive/MyDrive/genAI final - personal/marketing_sample_for_amazon_com-ecommerce__20200101_20200131__10k_data.csv'\n",
        "\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "print(\"First 5 rows of the DataFrame:\")\n",
        "print(df.head(3))\n",
        "print(\"\\nColumn names in the DataFrame:\")\n",
        "print(df.columns.tolist())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0dJmjRjDgfx"
      },
      "source": [
        "### Check for null columns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "htoBEDdlDcRh"
      },
      "outputs": [],
      "source": [
        "print(df.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LY0YChypDnma"
      },
      "source": [
        "## Filter to Toys/Games/Party/Crafts domain slice\n",
        "\n",
        "Our team has decided to use Toys/Games/Party/Crafts domain slice, which is a dominant slice in the dataset (>8000 rows)\n",
        "- Filter based on toy keywords to achieve the slice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ae6_wA7bDnPF"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# Filter to a Toys/Games/Party/Crafts domain slice\n",
        "#    (based on Category text keywords)\n",
        "# ============================================================\n",
        "\n",
        "toy_keywords = [\n",
        "    \"Toys\", \"Toy\", \"Game\", \"Games\", \"Puzzle\", \"Jigsaw\", \"Figure\", \"Figures\",\n",
        "    \"Doll\", \"Dolls\", \"Party\", \"Stuffed\", \"Plush\", \"Costume\", \"Craft\", \"Crafts\",\n",
        "    \"Kids\", \"Play\", \"Vehicle\", \"Learning\"\n",
        "]\n",
        "\n",
        "pattern = \"|\".join(toy_keywords)\n",
        "\n",
        "mask_toys = df[\"Category\"].str.contains(pattern, case=False, na=False)\n",
        "toys_df = df[mask_toys].copy()\n",
        "\n",
        "print(\"Toys/Party/Craft slice size:\", len(toys_df))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f9a03ce"
      },
      "source": [
        "## Prepare Products Data\n",
        "\n",
        "- Extract, Clean-up, and transform the relevant columns from the loaded CSV data to create a DataFrame for `products.parquet`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d90b6c13"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Initialize products_df\n",
        "products_df = pd.DataFrame({\n",
        "    'id': toys_df['Uniq Id'],\n",
        "    'title': toys_df['Product Name'],\n",
        "    'brand': toys_df['Brand Name'],\n",
        "    'category': toys_df['Category']\n",
        "})\n",
        "\n",
        "# Clean and convert 'Selling Price' to numeric for 'price' column\n",
        "products_df['price'] = toys_df['Selling Price'].astype(str).str.replace('$', '', regex=False).str.replace(',', '', regex=False)\n",
        "products_df['price'] = pd.to_numeric(products_df['price'], errors='coerce')\n",
        "\n",
        "# Initialize 'rating' column with NaN\n",
        "products_df['rating'] = np.nan\n",
        "# Fill the rating with random rating (numeric between 1-5)\n",
        "products_df['rating'] = np.random.randint(1, 6, size=len(products_df))\n",
        "\n",
        "# Concatenate text from relevant columns (not null) for 'features'\n",
        "feature_columns = [\n",
        "    'About Product',\n",
        "    'Product Specification',\n",
        "    'Technical Details'\n",
        "]\n",
        "\n",
        "# Fill NaN values with empty strings before concatenation\n",
        "products_df['features'] = toys_df[feature_columns].fillna('').agg(' '.join, axis=1)\n",
        "\n",
        "# Populate 'ingredients' column (but Ingredients column is all null)\n",
        "products_df['ingredients'] = toys_df['Ingredients']\n",
        "\n",
        "# Display the first few rows of products_df\n",
        "print(\"\\nFirst 5 rows of products_df:\")\n",
        "print(products_df.head())\n",
        "\n",
        "# Check data types and non-null counts for products_df\n",
        "print(\"\\nInfo for products_df:\")\n",
        "products_df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3dORhIRHjeO"
      },
      "outputs": [],
      "source": [
        "products_df.to_csv('products_df.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHLIoCGwFNNt"
      },
      "source": [
        "## Fill in Ingredients using Meta-Llama-3-8B-Instruct (keyword extraction from features column)\n",
        "\n",
        "Since ingredients are NaN in all rows, we will extract ingredients from features if available. If not, column value is filled as \"Unknown\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mcUsc7AXk6nd"
      },
      "source": [
        "Here is one example:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sPDtvzevkXWk"
      },
      "outputs": [],
      "source": [
        "products_df.iloc[1]['features']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2MQJCPLfk8hg"
      },
      "source": [
        "\"Plastic is made of corn and are 100% compostable\"\n",
        "We are expecting Llama to extract \"corn, plastic\" in this case.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QctZkgu9NVI3"
      },
      "outputs": [],
      "source": [
        "!pip install transformers accelerate sentencepiece --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLYZaRS7N8xQ"
      },
      "outputs": [],
      "source": [
        "# login to huggingface\n",
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dznwRqmGNCER"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "import torch\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    \"meta-llama/Meta-Llama-3-8B-Instruct\",\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B-Instruct\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PNYiNpcxGuwZ"
      },
      "outputs": [],
      "source": [
        "sample_df = products_df.copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ejnnx8ETFg6n"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Build context for each row\n",
        "def build_product_context(row):\n",
        "    parts = []\n",
        "    for col in [\"title\", \"features\"]:\n",
        "        if col in sample_df.columns:\n",
        "            val = row.get(col)\n",
        "        else:\n",
        "            val = None\n",
        "        if isinstance(val, str) and val.strip():\n",
        "            parts.append(val.strip())\n",
        "    return \"\\n\".join(parts)\n",
        "\n",
        "\n",
        "# LLM inference with HF Transformers\n",
        "\n",
        "def generate_ingredient_keywords(text: str) -> str:\n",
        "    if not isinstance(text, str) or not text.strip():\n",
        "        return \"unknown\"\n",
        "\n",
        "    system_prompt = (\n",
        "        \"You are an e-commerce data annotator.\\n\"\n",
        "        \"Given the product name and description, infer the likely main ingredients \"\n",
        "        \"or material-related keywords of the product.\\n\"\n",
        "        \"- Answer ONLY in concise English.\\n\"\n",
        "        \"- Output a comma-separated list (e.g., 'aloe vera, glycerin, water').\\n\"\n",
        "        \"- If it is not a consumable, cosmetic, household chemical, pet/baby product, \"\n",
        "        \"or you cannot infer ingredients, respond with 'unknown'.\"\n",
        "    )\n",
        "\n",
        "    user_prompt = f\"Product information:\\n{text}\\n\\nInferred ingredients or material keywords:\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_prompt},\n",
        "    ]\n",
        "\n",
        "    # LLaMA-3 chat template\n",
        "    prompt = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True,\n",
        "    )\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=64,\n",
        "            temperature=0.1,\n",
        "            do_sample=False,\n",
        "        )\n",
        "\n",
        "    # get just the response\n",
        "    gen_tokens = output[0][inputs[\"input_ids\"].shape[1]:]\n",
        "    answer = tokenizer.decode(gen_tokens, skip_special_tokens=True).strip()\n",
        "\n",
        "    # just the first row\n",
        "    answer = answer.split(\"\\n\")[0].strip()\n",
        "\n",
        "    lower = answer.lower()\n",
        "    if \"unknown\" in lower or \"not possible to infer\" in lower:\n",
        "        return \"unknown\"\n",
        "\n",
        "    # Clean up patterns like \"The answer is: polyester\"\n",
        "    for sep in [\"the answer is\", \"answer:\", \"answer is\"]:\n",
        "        if sep in lower:\n",
        "            idx = lower.find(sep)\n",
        "            answer = answer[idx + len(sep):].strip(\" :.\").strip()\n",
        "            break\n",
        "\n",
        "    return answer\n",
        "\n",
        "\n",
        "# Filter target rows with features\n",
        "mask = sample_df[\"features\"].notna()\n",
        "target_df = sample_df[mask]\n",
        "\n",
        "results = []\n",
        "\n",
        "print(f\"Target rows: {len(target_df)}\")\n",
        "\n",
        "\n",
        "# Run inference\n",
        "# Start with 20 rows for prompt tuning\n",
        "for i, (idx, row) in enumerate(target_df.iterrows(), start=1):\n",
        "    ctx = build_product_context(row)\n",
        "    ing_keywords = generate_ingredient_keywords(ctx)\n",
        "    results.append((idx, ing_keywords))\n",
        "\n",
        "    if i % 20 == 0:  # progress indicator\n",
        "        print(f\"Processed {i} rows.\")\n",
        "\n",
        "\n",
        "# Fill ingredients column\n",
        "for idx, ing_keywords in results:\n",
        "    sample_df.loc[idx, \"ingredients\"] = ing_keywords\n",
        "\n",
        "\n",
        "# Save result\n",
        "sample_df.to_csv(\"products_with_ingredients_generated.csv\", index=False)\n",
        "print(\"Saved: products_with_ingredients_generated.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blJIsMeu8kPP"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "sample_df = pd.read_csv('products_with_ingredients_generated.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gBsL-pqfkC03"
      },
      "source": [
        "Check that ingredients field is correctly populated"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OF6oq5p6-1Be"
      },
      "outputs": [],
      "source": [
        "sample_df.loc[0:5, 'ingredients']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SVtGbfYrlPaw"
      },
      "source": [
        "We also see \"corn, plastic\" correctly populated in the example we mentioned above."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3-Jf4hunImD"
      },
      "source": [
        "## Check the info on clean up df again\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X1r6hkekngvX"
      },
      "outputs": [],
      "source": [
        "sample_df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YLD67vKDozoX"
      },
      "source": [
        "## Fill in the \"Brands\" Column using Llama"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHO1EqwNo2EM"
      },
      "outputs": [],
      "source": [
        "# Build context for each row\n",
        "def build_product_context(row):\n",
        "    parts = []\n",
        "    for col in [\"title\", \"features\"]:\n",
        "        if col in sample_df.columns:\n",
        "            val = row.get(col)\n",
        "        else:\n",
        "            val = None\n",
        "        if isinstance(val, str) and val.strip():\n",
        "            parts.append(val.strip())\n",
        "    return \"\\n\".join(parts)\n",
        "\n",
        "\n",
        "# LLM inference with HF Transformers\n",
        "\n",
        "def generate_brand_name(text: str) -> str:\n",
        "    if not isinstance(text, str) or not text.strip():\n",
        "        return \"unknown\"\n",
        "\n",
        "    system_prompt = (\n",
        "        \"You are an e-commerce data annotator.\\n\"\n",
        "        \"Given the product name and description, infer the most likely BRAND NAME \"\n",
        "        \"or MANUFACTURER NAME of the product.\\n\"\n",
        "        \"- Answer ONLY with the brand/manufacturer name in concise English.\\n\"\n",
        "        \"- Do NOT include any extra words such as 'Brand:' or full sentences.\\n\"\n",
        "        \"- If you cannot infer a clear brand or manufacturer, respond with 'unknown'.\"\n",
        "    )\n",
        "\n",
        "    user_prompt = f\"Product information:\\n{text}\\n\\nInferred brand or manufacturer name:\"\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_prompt},\n",
        "    ]\n",
        "\n",
        "    # LLaMA-3 chat template\n",
        "    prompt = tokenizer.apply_chat_template(\n",
        "        messages,\n",
        "        tokenize=False,\n",
        "        add_generation_prompt=True,\n",
        "    )\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model.generate(\n",
        "            **inputs,\n",
        "            max_new_tokens=32,\n",
        "            temperature=0.1,\n",
        "            do_sample=False,\n",
        "        )\n",
        "\n",
        "    # get just the response\n",
        "    gen_tokens = output[0][inputs[\"input_ids\"].shape[1]:]\n",
        "    answer = tokenizer.decode(gen_tokens, skip_special_tokens=True).strip()\n",
        "\n",
        "    # just the first line\n",
        "    answer = answer.split(\"\\n\")[0].strip()\n",
        "\n",
        "    lower = answer.lower()\n",
        "    if \"unknown\" in lower or \"not possible to infer\" in lower:\n",
        "        return \"unknown\"\n",
        "\n",
        "    # Clean up patterns like \"The answer is: Disney\"\n",
        "    for sep in [\"the answer is\", \"answer:\", \"answer is\", \"brand:\", \"brand is\"]:\n",
        "        if sep in lower:\n",
        "            idx = lower.find(sep)\n",
        "            answer = answer[idx + len(sep):].strip(\" :.\").strip()\n",
        "            break\n",
        "\n",
        "    return answer\n",
        "\n",
        "\n",
        "# Filter target rows with features / title / description\n",
        "mask = (\n",
        "    sample_df.get(\"title\", \"\").notna()\n",
        "    | sample_df.get(\"features\", \"\").notna()\n",
        ")\n",
        "target_df = sample_df[mask]\n",
        "\n",
        "results = []\n",
        "\n",
        "print(f\"Target rows: {len(target_df)}\")\n",
        "\n",
        "\n",
        "# Run inference\n",
        "# Start with 20 rows for prompt tuning\n",
        "for i, (idx, row) in enumerate(target_df.iterrows(), start=1):\n",
        "    ctx = build_product_context(row)\n",
        "    brand_name = generate_brand_name(ctx)\n",
        "    results.append((idx, brand_name))\n",
        "\n",
        "    if i % 20 == 0:  # progress indicator\n",
        "        print(f\"Processed {i} rows.\")\n",
        "\n",
        "\n",
        "# Fill brand_generated column\n",
        "if \"brand\" not in sample_df.columns:\n",
        "    sample_df[\"brand\"] = None\n",
        "\n",
        "for idx, brand_name in results:\n",
        "    sample_df.loc[idx, \"brand\"] = brand_name\n",
        "\n",
        "\n",
        "# Save result\n",
        "sample_df.to_csv(\"products_with_brand_generated.csv\", index=False)\n",
        "print(\"Saved: products_with_brand_generated.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KTR4_6J1WYw3"
      },
      "outputs": [],
      "source": [
        "print(\"First 5 rows of products_df:\")\n",
        "print(sample_df['brand'].head(5))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dkv1f-XgXL5r"
      },
      "source": [
        "## Clean-up \"Features\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VxnbkEGYYGGd"
      },
      "outputs": [],
      "source": [
        "sample_df['features'].head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lWvqGt7TXPMW"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "\n",
        "def clean_features(text: str) -> str:\n",
        "    if not isinstance(text, str):\n",
        "        return text\n",
        "\n",
        "    # 1. Remove the repeated default Amazon phrase\n",
        "    prefix = \"Make sure this fits by entering your model number. | \"\n",
        "    if text.startswith(prefix):\n",
        "        text = text[len(prefix):]\n",
        "\n",
        "    # 2. Remove emojis / non-ASCII characters\n",
        "    # Keep only ASCII characters\n",
        "    text = text.encode(\"ascii\", \"ignore\").decode()\n",
        "\n",
        "    # 3. Strip whitespace\n",
        "    text = text.strip()\n",
        "\n",
        "    # 4. Remove double spaces\n",
        "    text = re.sub(r\"\\s+\", \" \", text)\n",
        "\n",
        "    return text if text else None\n",
        "\n",
        "\n",
        "# Apply to the whole column\n",
        "sample_df[\"features\"] = sample_df[\"features\"].apply(clean_features)\n",
        "\n",
        "print(\"Done cleaning!\")\n",
        "sample_df[\"features\"].head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6doBbVXrbpP0"
      },
      "source": [
        "## Merge Rating fetched from Google Shopping API\n",
        "Our group was able to fetch first 1200 rows' rating from the API, but was limited due to API # of request restriction on the free account.\n",
        "\n",
        "We will merge these 1200 results, but randomly generate the rating for the rest of the products"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qUeTdxVIbyic"
      },
      "outputs": [],
      "source": [
        "rating_df = pd.read_csv('/content/Amazon_Product_Dataset_with_Rating.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h2jji-uBb6X0"
      },
      "outputs": [],
      "source": [
        "rating_df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EE7RZ768d5lR"
      },
      "outputs": [],
      "source": [
        "# print number of nan in rating_df[\"rating\"]\n",
        "print(rating_df[\"rating\"].isna().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rcIufzPaeJQt"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# 1) Merge rating_df ratings into cleaned_df\n",
        "merged = sample_df.merge(\n",
        "    rating_df[[\"id\", \"rating\"]],\n",
        "    on=\"id\",\n",
        "    how=\"left\",\n",
        "    suffixes=(\"\", \"_real\")\n",
        ")\n",
        "\n",
        "# 2) Fill NaN rating with random numbers\n",
        "missing_mask = merged[\"rating_real\"].isna()\n",
        "merged.loc[missing_mask, \"rating_real\"] = np.round(np.random.uniform(1.0, 5.0, size=missing_mask.sum()), 1)\n",
        "\n",
        "# 3) Ensure final rating is float\n",
        "merged[\"rating\"] = merged[\"rating_real\"].astype(float)\n",
        "\n",
        "# Drop helper column\n",
        "merged = merged.drop(columns=[\"rating_real\"])\n",
        "\n",
        "merged.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcwSkBp0XwiF"
      },
      "source": [
        "## Final Review of the Cleaned Data and Export as CSV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtbizcfRXz60"
      },
      "outputs": [],
      "source": [
        "merged.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4WpUe86IX7ZT"
      },
      "outputs": [],
      "source": [
        "merged.to_csv('products_df_merged_cleaned.csv', index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dff17c9b"
      },
      "source": [
        "## Save Products Data to Parquet\n",
        "\n",
        "Save the prepared products DataFrame to a Parquet file named `products.parquet`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6613b96f"
      },
      "outputs": [],
      "source": [
        "merged.to_parquet('products.parquet', index=False)\n",
        "print(\"merged successfully saved to 'products.parquet'\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "langchain_env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}